{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yP2Hnz0itmHE",
    "outputId": "0705fac0-a514-4049-85c1-555672dd41be",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install PyTDC rdkit==2023.03.1 DeepChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only if needed:\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2PgXFV9zZrB"
   },
   "outputs": [],
   "source": [
    "from tdc.single_pred import ADME\n",
    "import rdkit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit.Chem import PandasTools, Descriptors, AllChem, AddHs, MolFromSmiles\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "from deepchem.feat import RDKitDescriptors\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from collections import defaultdict, Counter\n",
    "import os, sys, shutil, random, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_split(test,train):\n",
    "    \"\"\"Takes the train-test split and splits into: \n",
    "    X_train, X_test, y_train and y_test, where Dimensionality is separated into y_train and y_test.\"\"\"\n",
    "    y_test=test['ro5']\n",
    "    y_train=train['ro5']\n",
    "    X_test=test.drop(columns='ro5')\n",
    "    X_train=train.drop(columns='ro5')\n",
    "    return(X_train, X_test, y_train, y_test)\n",
    "\n",
    "def model_analysis(y_pred_train,y_pred,y_test,y_train):\n",
    "    \"\"\"Calculation of performance metrics\"\"\"\n",
    "    con_mtrx=confusion_matrix(y_test, y_pred)\n",
    "    prec=precision_score(y_test, y_pred,average=None)\n",
    "    reca=recall_score(y_test, y_pred,average=None)\n",
    "    f1 = f1_score(y_test, y_pred, average=None)\n",
    "    return reca,prec,f1\n",
    "\n",
    "def model_para(est_,mxdp_,est,mxdp,rnd_data,rnddata):\n",
    "    \"\"\"Function to store model parameters like n_estimators, max_depth and\n",
    "    rnd state for data splits and model training.\"\"\"\n",
    "    # Appending parameters to the list:\n",
    "    est_.append(est)\n",
    "    mxdp_.append(mxdp)\n",
    "    #rndmodel.append(rnd_model)\n",
    "    rnddata.append(rnd_data)\n",
    "    return est_,mxdp_,rnddata\n",
    "\n",
    "def display_result(reca,prec,f1,est_,mxdp_,rnddata):\n",
    "    \"\"\"Function to display results. \"\"\"\n",
    "    # Create a dataframe\n",
    "    df=pd.DataFrame()\n",
    "    # Store parameters and metrics in a dataframe\n",
    "    df[\"est\"]=est_\n",
    "    df[\"maxdepth\"]=mxdp_\n",
    "    df[\"rnd_datasplit\"]=rnddata\n",
    "    #df[\"rnd_model\"]=rndmodel\n",
    "    df[\"F1_score\"]=f1\n",
    "    ind=['index','test_data']\n",
    "    df_rfc=df\n",
    "    #display the dataframe\n",
    "    display(df_rfc)\n",
    "    # display tables for metrics: precision, recall and F1 score\n",
    "    for tbl,tbl_name in zip([prec,reca,f1],['Precision','Recall','F1 score']):#display precision recall\n",
    "        a=pd.DataFrame(tbl)\n",
    "        new_cols = ['0', '1']  # metrics for each class\n",
    "        new_names_map = {a.columns[i]:new_cols[i] for i in range(len(new_cols))} # dict to rename columns by classes \n",
    "        a.rename(new_names_map, axis=1, inplace=True)  # rename the columns\n",
    "        # display name, table and the statistics of the table for no_runs:\n",
    "        display(tbl_name)  \n",
    "        display(a)\n",
    "        display(a.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df,no_runs,fname_save): \n",
    "    \"\"\" Function to train a RandomForest Classifier.\n",
    "    First, an outer split of the dataset is created and then the inner split based on StratifiedKFold.\n",
    "    For each inner split, hyperparameters are tuned to obtain the best model parameters.\n",
    "    For these model parameters, RFC object is initialized and fit on the outer training split.\n",
    "    Model analysis is performed to obtain precision, recall and f1 score.\n",
    "    \n",
    "    return: precision, recall, f1-score.\"\"\"\n",
    "    \n",
    "    print('-----'+fname_save+'Model-----')\n",
    "    # empty list to store metrics, parameters and rnd state:\n",
    "    std,mean,accuracy,ac_test,ac_train,est_,mxdp_,rndmodel,rnddata,reca_list,prec_list,f1_list=([] for i in range(12))\n",
    "    # An array of n_estimators and max_depth for hyperparameter tuning:\n",
    "    n_estimators = range(10,100,20)\n",
    "    max_depth = range(1,15,2)\n",
    "    k = 5    # number of K-folds\n",
    "    prec_dict = defaultdict(list)\n",
    "    reca_dict = defaultdict(list)\n",
    "    f1_dict = defaultdict(list)\n",
    "    # Enter the loop for number of runs:\n",
    "    for mi in range(0,no_runs):\n",
    "        \n",
    "        rnd_data = random.randint(1,200)   # rnd state for data split\n",
    "        # train-test split stratified over dimensionality\n",
    "        train, test = train_test_split(df, test_size=0.2, stratify=df['ro5'],shuffle=True,random_state=rnd_data) \n",
    "        X_train, X_test, y_train, y_test=xy_split(test,train)    # Splitting into X and y \n",
    "    #     print(y_train.value_counts())\n",
    "    #     print(y_test.value_counts())\n",
    "    #    print(df['Dimensionality'].value_counts())\n",
    "    #    sys.exit()\n",
    "        # Scale the features \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)  # only transform. No fit()\n",
    "        # convert to numpy array for consistency\n",
    "        y_train = y_train.to_numpy()\n",
    "        y_test = y_test.to_numpy()\n",
    "\n",
    "        # Initialize StratifiedKFold object\n",
    "        strat_Kfold = StratifiedKFold(n_splits=k, shuffle=True, random_state=rnd_data)  # 5-fold stratified split (so called, 'inner split')\n",
    "        # Cross validation loop:\n",
    "        for train_idx, test_idx in strat_Kfold.split(X_train, y_train):  # loop over the 5 train and test indexes\n",
    "            #print(train_idx)\n",
    "            #print(test_idx)\n",
    "            X_trn, X_tst = X_train[train_idx].copy(), X_train[test_idx].copy()    # generate the X split based on indexes\n",
    "            y_trn, y_tst = y_train[train_idx].copy(), y_train[test_idx].copy()   # generate the y split based on indexes\n",
    "\n",
    "            # Training hyperparameters\n",
    "            for n_est in n_estimators:  # for 5 different n_est values\n",
    "                for mx_depth in max_depth:  # for 5 different max_depth values\n",
    "                    # initialize RandomForestClassifier object for a given set of params\n",
    "                    clf = RandomForestClassifier(n_estimators=n_est,max_depth=mx_depth,bootstrap=False,random_state=rnd_data)  \n",
    "                    clf.fit(X_trn, y_trn)  # fit the RF model based on the inner training set\n",
    "                    y_pred_train=clf.predict(X_trn)   # predictions on the inner training set\n",
    "                    y_pred=clf.predict(X_tst)  # predictions on the inner test set\n",
    "                    reca,prec,f1=model_analysis(y_pred_train,y_pred,y_tst,y_trn)  # get model's performance metrics\n",
    "                    reca_dict[n_est,mx_depth].append(np.mean(reca))\n",
    "                    prec_dict[n_est,mx_depth].append(np.mean(prec))\n",
    "                    f1_dict[n_est,mx_depth].append(np.mean(f1))\n",
    "        #sys.exit()\n",
    "        # Calculate the mean of the metrics for all 5 folds\n",
    "        cv_prec_mean = {k:np.mean(v) for k, v in prec_dict.items()}\n",
    "        cv_reca_mean = {k:np.mean(v) for k, v in reca_dict.items()}\n",
    "        cv_f1_mean = {k:np.mean(v) for k, v in f1_dict.items()}\n",
    "#         print(cv_prec_mean)\n",
    "#         sys.exit()\n",
    "\n",
    "        # Model selection is based on f1-score\n",
    "#         model_idx = np.unravel_index(cv_f1_mean.argmax(), cv_f1_mean.shape)   # get the index where f1-score is maximum\n",
    "        model_params = max(cv_f1_mean,key=cv_f1_mean.get)\n",
    "#         print(model_idx)\n",
    "#         print(model_idx[0])\n",
    "#         print(type(model_idx))\n",
    "#         sys.exit()\n",
    "        best_n_est = model_params[0]   # the 0th index corresponds to the best n-estimators\n",
    "        best_mx_depth = model_params[1]   # the 1st index corresponds to the best max_depth      \n",
    "        #print('best max_depth: ',best_mx_depth)\n",
    "        #print('best n_estimators: ',best_n_est)\n",
    "        # initialize RandomForestClassifier object for optimized set of params\n",
    "        rfc = RandomForestClassifier(n_estimators=best_n_est,max_depth=best_mx_depth,bootstrap=False,random_state=rnd_data)  # RFC object based on tuned hyperparameters\n",
    "        rfc.fit(X_train, y_train)   # model fitting on the outer split data\n",
    "        y_pred_train=rfc.predict(X_train)   # prediction on outer training split\n",
    "        y_pred=rfc.predict(X_test)   # prediction on outer test split\n",
    "        # calculate and store the metrics\n",
    "        reca_,prec_,f1_=model_analysis(y_pred_train,y_pred,y_test,y_train)\n",
    "        reca_list.append(reca_)\n",
    "        prec_list.append(prec_)\n",
    "        f1_list.append(f1_)\n",
    "        # store model parameters \n",
    "        est_,mxdp_,rnddata=model_para(est_,mxdp_,best_n_est,best_mx_depth,rnd_data,rnddata)\n",
    "\n",
    "        # Saving the model:\n",
    "        filename = fname_save+'_model_'+str(mi)+'.pkl'\n",
    "        pickle.dump(rfc, open('pickle_model/'+filename, 'wb'))\n",
    "    print('...models saved...')\n",
    "    \n",
    "    # display the results in a table format\n",
    "    display_result(reca_list,prec_list,f1_list,est_,mxdp_,rnddata)  \n",
    "    \n",
    "    # find the median model\n",
    "    q=[(ii[0],np.mean(ii[1])) for ii in enumerate(f1_list)]   # stores the index and the mean f1-score for each model\n",
    "    sorted_f1 = sorted(q, key=lambda tup: tup[1])    # sorts the list along the mean f1-score\n",
    "    model=sorted_f1[int(no_runs/2)][0]    # the median model is the mid of the sorted list\n",
    "    fnmedian=fname_save+'_model_'+str(model)+'.pkl'   # the name of the median model\n",
    "    \n",
    "    #return the median model for predictions\n",
    "    return fnmedian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 184
    },
    "id": "YPVauX9TxTBW",
    "outputId": "c5a0d36a-ec2d-4195-cf1c-7b1b091f6b37",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get data from TDC's ADME\n",
    "data = ADME(name = 'Caco2_Wang')\n",
    "data.get_data().head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BLkfwr46G2sk",
    "outputId": "c9cd71b4-ea16-4149-d3b7-7bbf3512e5ab"
   },
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "-dooIZm2HBH3",
    "outputId": "ef56c6bc-41a7-4a6b-94f6-2c0c8fdc4771"
   },
   "outputs": [],
   "source": [
    "# Get data from the object\n",
    "drugs = data.get_data()\n",
    "drugs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs['Drug'] = [convert_smiles_to_canonical(sm) for sm in drugs['Drug'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(drugs['Drug'].to_list()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs['Drug'].to_list()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's add the Mol objecets to the dataframe by reading smiles\n",
    "drugs['Molecule'] = [MolFromSmiles(sm) for sm in drugs['Drug'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "IyXMe5hlHP0u",
    "outputId": "43d9ccd7-6073-4cbc-a9bc-b6cdf958abc1"
   },
   "outputs": [],
   "source": [
    "drugs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kgIJwlupHkKJ"
   },
   "outputs": [],
   "source": [
    "# There are no hydrogens in these structures. \n",
    "drugs['Molecule'] = [AddHs(mol) for mol in drugs['Molecule'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 167
    },
    "id": "R3eXJJn9JKg6",
    "outputId": "cc0ffae4-fc1e-4182-853f-0924bf4bf186"
   },
   "outputs": [],
   "source": [
    "drugs.Molecule.iloc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gaw4bdjNJigt"
   },
   "source": [
    "### Lipinski's rule of 5:\n",
    "#### Poor absorption is likely if the molecule violates more than one of the following conditions:\n",
    "#### 1. Molecular Weight <= 500 Da\n",
    "#### 2. No. Hydrogen Bond Donors <= 10\n",
    "#### 3. No. Hydrogen Bond Acceptors <= 5\n",
    "#### 4. LogP <= 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Go3LDVcJJ87v"
   },
   "outputs": [],
   "source": [
    "def ro5_check(mol):\n",
    "    MW = Descriptors.MolWt(mol)\n",
    "    HBA = Descriptors.NOCount(mol)\n",
    "    HBD = Descriptors.NHOHCount(mol)\n",
    "    LogP = Descriptors.MolLogP(mol)\n",
    "    conditions = [MW <= 500, HBA <= 10, HBD <= 5, LogP <= 5]\n",
    "    pass_ro5 = conditions.count(True) >= 3\n",
    "    return pass_ro5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZCxrckmKTSa"
   },
   "source": [
    "#### Let's make a new category to sort out all the drugs that violate the ro5\n",
    "#### If it follows ro5, the category = 1 else 0\n",
    "#### It should be noted that ro5 doesn't always hold true. But we assume it to hold true here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TarAk6jIKitU"
   },
   "outputs": [],
   "source": [
    "# Adding a category column 'ro5' where 1 indicates pass and 0 is fail\n",
    "drugs['ro5'] = [1 if ro5_check(mol)==True else 0 for mol in drugs['Molecule'].to_list()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "id": "7ceNYfXhLZ9p",
    "outputId": "9ed02866-32b0-4ed6-a26a-ca782e763ee2"
   },
   "outputs": [],
   "source": [
    "drugs.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TpnYDgWQLqtp"
   },
   "outputs": [],
   "source": [
    "# Let's look at the descriptors\n",
    "des_keys = Descriptors.CalcMolDescriptors(drugs.Molecule[0]).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yao9AWTjL7FY",
    "outputId": "6c7cb519-5f8c-4067-a0b3-91b07114650b"
   },
   "outputs": [],
   "source": [
    "des_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ51G1btWiiT"
   },
   "source": [
    "### Let's use DeepChem to generate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f5iaaP_SZFEs"
   },
   "outputs": [],
   "source": [
    "rdkit_featurizer = RDKitDescriptors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RO1jmaZYahNA",
    "outputId": "b0b2c7ad-d9d4-405d-eda2-943546b11236"
   },
   "outputs": [],
   "source": [
    "mol = drugs['Molecule'].to_list()[0]\n",
    "type(rdkit_featurizer.featurize(mol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209
    },
    "id": "HqKNNxUrbblP",
    "outputId": "4598403f-7f6b-4140-a9a5-d75e230e756f"
   },
   "outputs": [],
   "source": [
    "# Generate descriptors into columns\n",
    "for idx, mol in enumerate(drugs.Molecule):\n",
    "    all_des = Descriptors.CalcMolDescriptors(mol)\n",
    "    for des in des_keys:\n",
    "        drugs.loc[idx,des] = all_des[des]\n",
    "\n",
    "drugs.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugs.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vxzZlE4PmsS1"
   },
   "outputs": [],
   "source": [
    "# selecting a subset of features\n",
    "clean_df = drugs[['MolWt','NumValenceElectrons','NumHAcceptors','NumHDonors','NumAromaticRings','MolLogP','Y','ro5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "DfZtcIffo7LC",
    "outputId": "cf0084a0-b688-47fb-94ed-e258118cf128"
   },
   "outputs": [],
   "source": [
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "Jz7ZMG53rDVi",
    "outputId": "482a1100-9422-4335-a0ec-c51ded87d65d"
   },
   "outputs": [],
   "source": [
    "# Make pairplots of Y vs. features\n",
    "plt.figure(figsize=(8,20))\n",
    "sns.set(rc={'axes.labelsize': 16, 'xtick.labelsize': 14, 'ytick.labelsize': 14})\n",
    "sns.pairplot(data = clean_df,\n",
    "                x_vars = ['MolWt', 'NumValenceElectrons', \n",
    "                              'NumHAcceptors', 'NumHDonors', 'MolLogP'],\n",
    "                y_vars = ['Y'],\n",
    "                hue='ro5',\n",
    "                plot_kws = {'alpha':.6})\n",
    "#plt.savefig('features_pair_plot.png',dpi=500)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More EDA will be in another notebook! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe with features and target 'ro5'\n",
    "df_6_fea = clean_df[['MolWt','NumValenceElectrons','NumHAcceptors','NumHDonors','NumAromaticRings','MolLogP','ro5']]\n",
    "df_6_fea.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_runs = 10\n",
    "fname = '6_fea'\n",
    "train_model(df_6_fea,no_runs,fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBNmDXslzca3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SZkDnanSzchl"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
